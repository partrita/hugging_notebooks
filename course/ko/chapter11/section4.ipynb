{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z-6LLOPZouLg"
   },
   "source": [
    "# Hugging Face TRLì„ ì‚¬ìš©í•˜ì—¬ LoRA ì–´ëŒ‘í„°ë¡œ LLM ë¯¸ì„¸ ì¡°ì •í•˜ëŠ” ë°©ë²•\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ LoRA(Low-Rank Adaptation) ì–´ëŒ‘í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì„ íš¨ìœ¨ì ìœ¼ë¡œ ë¯¸ì„¸ ì¡°ì •í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. LoRAëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë§¤ê°œë³€ìˆ˜ íš¨ìœ¨ì ì¸ ë¯¸ì„¸ ì¡°ì • ê¸°ë²•ì…ë‹ˆë‹¤.\n",
    "- ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ ê³ ì •\n",
    "- ì–´í…ì…˜ ë ˆì´ì–´ì— ì‘ì€ í›ˆë ¨ ê°€ëŠ¥í•œ ìˆœìœ„ ë¶„í•´ í–‰ë ¬ ì¶”ê°€\n",
    "- ì¼ë°˜ì ìœ¼ë¡œ í›ˆë ¨ ê°€ëŠ¥í•œ ë§¤ê°œë³€ìˆ˜ë¥¼ ì•½ 90% ì¤„ì…ë‹ˆë‹¤.\n",
    "- ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì´ë©´ì„œ ëª¨ë¸ ì„±ëŠ¥ ìœ ì§€\n",
    "\n",
    "ë‹¤ë£° ë‚´ìš©:\n",
    "1. ê°œë°œ í™˜ê²½ ë° LoRA êµ¬ì„± ì„¤ì •\n",
    "2. ì–´ëŒ‘í„° í›ˆë ¨ì„ ìœ„í•œ ë°ì´í„° ì„¸íŠ¸ ìƒì„± ë° ì¤€ë¹„\n",
    "3. `trl` ë° `SFTTrainer`ì™€ LoRA ì–´ëŒ‘í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¯¸ì„¸ ì¡°ì •\n",
    "4. ëª¨ë¸ í…ŒìŠ¤íŠ¸ ë° ì–´ëŒ‘í„° ë³‘í•©(ì„ íƒ ì‚¬í•­)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXqd9BXgouLi"
   },
   "source": [
    "## 1. ê°œë°œ í™˜ê²½ ì„¤ì •\n",
    "\n",
    "ì²« ë²ˆì§¸ ë‹¨ê³„ëŠ” trl, transformers, datasetsë¥¼ í¬í•¨í•˜ì—¬ Hugging Face ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ Pytorchë¥¼ ì„¤ì¹˜í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì•„ì§ trlì— ëŒ€í•´ ë“¤ì–´ë³¸ ì ì´ ì—†ë‹¤ë©´ ê±±ì •í•˜ì§€ ë§ˆì‹­ì‹œì˜¤. ì´ëŠ” transformers ë° datasets ìœ„ì— ìˆëŠ” ìƒˆë¡œìš´ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, ê°œë°©í˜• LLMì„ ë¯¸ì„¸ ì¡°ì •, rlhf, ì •ë ¬í•˜ëŠ” ê²ƒì„ ë” ì‰½ê²Œ ë§Œë“­ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tKvGVxImouLi"
   },
   "outputs": [],
   "source": [
    "# Google Colabì—ì„œ ìš”êµ¬ ì‚¬í•­ ì„¤ì¹˜\n",
    "# !pip install transformers datasets trl huggingface_hub\n",
    "\n",
    "# Hugging Faceì— ì¸ì¦\n",
    "\n",
    "from huggingface_hub import login\n",
    "\n",
    "login()\n",
    "\n",
    "# í¸ì˜ë¥¼ ìœ„í•´ í—ˆë¸Œ í† í°ì„ HF_TOKENìœ¼ë¡œ í™˜ê²½ ë³€ìˆ˜ì— ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XHUzfwpKouLk"
   },
   "source": [
    "## 2. ë°ì´í„° ì„¸íŠ¸ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "z4p6Bvo7ouLk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['full_topic', 'messages'],\n",
       "        num_rows: 2260\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['full_topic', 'messages'],\n",
       "        num_rows: 119\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ìƒ˜í”Œ ë°ì´í„° ì„¸íŠ¸ ë¡œë“œ\n",
    "from datasets import load_dataset\n",
    "\n",
    "# TODO: path ë° name ë§¤ê°œë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ì„¸íŠ¸ ë° êµ¬ì„±ì„ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "dataset = load_dataset(path=\"HuggingFaceTB/smoltalk\", name=\"everyday-conversations\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TOhJdtsouLk"
   },
   "source": [
    "## 3. `trl` ë° LoRAê°€ í¬í•¨ëœ `SFTTrainer`ë¥¼ ì‚¬ìš©í•˜ì—¬ LLM ë¯¸ì„¸ ì¡°ì •\n",
    "\n",
    "`trl`ì˜ [SFTTrainer](https://huggingface.co/docs/trl/sft_trainer)ëŠ” [PEFT](https://huggingface.co/docs/peft/en/index) ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í†µí•´ LoRA ì–´ëŒ‘í„°ì™€ì˜ í†µí•©ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ ì„¤ì •ì˜ ì£¼ìš” ì´ì ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
    "\n",
    "1. **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**:\n",
    "   - ì–´ëŒ‘í„° ë§¤ê°œë³€ìˆ˜ë§Œ GPU ë©”ëª¨ë¦¬ì— ì €ì¥ë©ë‹ˆë‹¤.\n",
    "   - ê¸°ë³¸ ëª¨ë¸ ê°€ì¤‘ì¹˜ëŠ” ê³ ì •ëœ ìƒíƒœë¡œ ìœ ì§€ë˜ë©° ë” ë‚®ì€ ì •ë°€ë„ë¡œ ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "   - ì†Œë¹„ì GPUì—ì„œ ëŒ€ê·œëª¨ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "2. **í›ˆë ¨ ê¸°ëŠ¥**:\n",
    "   - ìµœì†Œí•œì˜ ì„¤ì •ìœ¼ë¡œ ê¸°ë³¸ PEFT/LoRA í†µí•©\n",
    "   - ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ ë”ìš± í–¥ìƒì‹œí‚¤ëŠ” QLoRA(ì–‘ìí™”ëœ LoRA) ì§€ì›\n",
    "\n",
    "3. **ì–´ëŒ‘í„° ê´€ë¦¬**:\n",
    "   - ì²´í¬í¬ì¸íŠ¸ ì¤‘ ì–´ëŒ‘í„° ê°€ì¤‘ì¹˜ ì €ì¥\n",
    "   - ì–´ëŒ‘í„°ë¥¼ ê¸°ë³¸ ëª¨ë¸ì— ë‹¤ì‹œ ë³‘í•©í•˜ëŠ” ê¸°ëŠ¥\n",
    "\n",
    "ì˜ˆì œì—ì„œëŠ” LoRAë¥¼ ì‚¬ìš©í•˜ë©°, LoRAì™€ 4ë¹„íŠ¸ ì–‘ìí™”ë¥¼ ê²°í•©í•˜ì—¬ ì„±ëŠ¥ ì €í•˜ ì—†ì´ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ë”ìš± ì¤„ì…ë‹ˆë‹¤. ì„¤ì •ì—ëŠ” ëª‡ ê°€ì§€ êµ¬ì„± ë‹¨ê³„ë§Œ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "1. LoRA êµ¬ì„± ì •ì˜(ìˆœìœ„, ì•ŒíŒŒ, ë“œë¡­ì•„ì›ƒ)\n",
    "2. PEFT êµ¬ì„±ìœ¼ë¡œ SFTTrainer ìƒì„±\n",
    "3. ì–´ëŒ‘í„° ê°€ì¤‘ì¹˜ í›ˆë ¨ ë° ì €ì¥\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ê°€ì ¸ì˜¤ê¸°\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from trl import SFTConfig, SFTTrainer, setup_chat_format\n",
    "import torch\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "model_name = \"HuggingFaceTB/SmolLM2-135M\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=model_name\n",
    ").to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_name)\n",
    "\n",
    "# ì±„íŒ… í˜•ì‹ ì„¤ì •\n",
    "model, tokenizer = setup_chat_format(model=model, tokenizer=tokenizer)\n",
    "\n",
    "# ë¯¸ì„¸ ì¡°ì •ì„ ì €ì¥í•˜ê±°ë‚˜ ì—…ë¡œë“œí•  ì´ë¦„ ì„¤ì •\n",
    "finetune_name = \"SmolLM2-FT-MyDataset\"\n",
    "finetune_tags = [\"smol-course\", \"module_1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZbuVArTHouLk"
   },
   "source": [
    "`SFTTrainer`ëŠ” `peft`ì™€ì˜ ê¸°ë³¸ í†µí•©ì„ ì§€ì›í•˜ë¯€ë¡œ LoRA ë“±ì„ ì‚¬ìš©í•˜ì—¬ LLMì„ íš¨ìœ¨ì ìœ¼ë¡œ ì¡°ì •í•˜ëŠ” ê²ƒì´ ë§¤ìš° ì‰½ìŠµë‹ˆë‹¤. `LoraConfig`ë¥¼ ë§Œë“¤ê³  íŠ¸ë ˆì´ë„ˆì—ê²Œ ì œê³µí•˜ê¸°ë§Œ í•˜ë©´ ë©ë‹ˆë‹¤.\n",
    "\n",
    "<div style='background-color: lightblue; padding: 10px; border-radius: 5px; margin-bottom: 20px; color:black'>\n",
    "    <h2 style='margin: 0;color:blue'>ì—°ìŠµ: ë¯¸ì„¸ ì¡°ì •ì„ ìœ„í•œ LoRA ë§¤ê°œë³€ìˆ˜ ì •ì˜</h2>\n",
    "    <p>Hugging Face í—ˆë¸Œì—ì„œ ë°ì´í„° ì„¸íŠ¸ë¥¼ ê°€ì ¸ì™€ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•©ë‹ˆë‹¤. </p>\n",
    "    <p><b>ë‚œì´ë„</b></p>\n",
    "    <p>ğŸ¢ ì„ì˜ì˜ ë¯¸ì„¸ ì¡°ì •ì„ ìœ„í•œ ì¼ë°˜ì ì¸ ë§¤ê°œë³€ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.</p>\n",
    "    <p>ğŸ• ë§¤ê°œë³€ìˆ˜ë¥¼ ì¡°ì •í•˜ê³  ê°€ì¤‘ì¹˜ ë° í¸í–¥ì—ì„œ ê²€í† í•©ë‹ˆë‹¤.</p>\n",
    "    <p>ğŸ¦ ë§¤ê°œë³€ìˆ˜ë¥¼ ì¡°ì •í•˜ê³  ì¶”ë¡  ê²°ê³¼ì˜ ë³€í™”ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "blDSs9swouLk"
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "# TODO: LoRA ë§¤ê°œë³€ìˆ˜ êµ¬ì„±\n",
    "# r: LoRA ì—…ë°ì´íŠ¸ í–‰ë ¬ì˜ ìˆœìœ„ ì°¨ì›(ì‘ì„ìˆ˜ë¡ ì••ì¶•ë¥ ì´ ë†’ì•„ì§)\n",
    "rank_dimension = 6\n",
    "# lora_alpha: LoRA ë ˆì´ì–´ì˜ ìŠ¤ì¼€ì¼ë§ íŒ©í„°(ë†’ì„ìˆ˜ë¡ ì ì‘ë ¥ì´ ê°•í•´ì§)\n",
    "lora_alpha = 8\n",
    "# lora_dropout: LoRA ë ˆì´ì–´ì˜ ë“œë¡­ì•„ì›ƒ í™•ë¥ (ê³¼ì í•© ë°©ì§€ì— ë„ì›€)\n",
    "lora_dropout = 0.05\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=rank_dimension,  # ìˆœìœ„ ì°¨ì› - ì¼ë°˜ì ìœ¼ë¡œ 4-32 ì‚¬ì´\n",
    "    lora_alpha=lora_alpha,  # LoRA ìŠ¤ì¼€ì¼ë§ íŒ©í„° - ì¼ë°˜ì ìœ¼ë¡œ ìˆœìœ„ì˜ 2ë°°\n",
    "    lora_dropout=lora_dropout,  # LoRA ë ˆì´ì–´ì˜ ë“œë¡­ì•„ì›ƒ í™•ë¥ \n",
    "    bias=\"none\",  # LoRAì˜ í¸í–¥ ìœ í˜•. í•´ë‹¹ í¸í–¥ì€ í›ˆë ¨ ì¤‘ì— ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤.\n",
    "    target_modules=\"all-linear\",  # LoRAë¥¼ ì ìš©í•  ëª¨ë“ˆ\n",
    "    task_type=\"CAUSAL_LM\",  # ëª¨ë¸ ì•„í‚¤í…ì²˜ì˜ ì‘ì—… ìœ í˜•\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5NUDPcaouLl"
   },
   "source": [
    "í›ˆë ¨ì„ ì‹œì‘í•˜ê¸° ì „ì— ì‚¬ìš©í•  í•˜ì´í¼íŒŒë¼ë¯¸í„°(`TrainingArguments`)ë¥¼ ì •ì˜í•´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NqT28VZlouLl"
   },
   "outputs": [],
   "source": [
    "# í›ˆë ¨ êµ¬ì„±\n",
    "# QLoRA ë…¼ë¬¸ ê¶Œì¥ ì‚¬í•­ì— ê¸°ë°˜í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
    "args = SFTConfig(\n",
    "    # ì¶œë ¥ ì„¤ì •\n",
    "    output_dir=finetune_name,  # ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì €ì¥í•  ë””ë ‰í„°ë¦¬\n",
    "    # í›ˆë ¨ ê¸°ê°„\n",
    "    num_train_epochs=1,  # í›ˆë ¨ ì—í¬í¬ ìˆ˜\n",
    "    # ë°°ì¹˜ í¬ê¸° ì„¤ì •\n",
    "    per_device_train_batch_size=2,  # GPUë‹¹ ë°°ì¹˜ í¬ê¸°\n",
    "    gradient_accumulation_steps=2,  # ë” í° ìœ íš¨ ë°°ì¹˜ë¥¼ ìœ„í•´ ê¸°ìš¸ê¸° ëˆ„ì \n",
    "    # ë©”ëª¨ë¦¬ ìµœì í™”\n",
    "    gradient_checkpointing=True,  # ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ê³„ì‚°ëŸ‰ ì ˆì¶©\n",
    "    # ì˜µí‹°ë§ˆì´ì € ì„¤ì •\n",
    "    optim=\"adamw_torch_fused\",  # íš¨ìœ¨ì„±ì„ ìœ„í•´ ìœµí•©ëœ AdamW ì‚¬ìš©\n",
    "    learning_rate=2e-4,  # í•™ìŠµë¥ (QLoRA ë…¼ë¬¸)\n",
    "    max_grad_norm=0.3,  # ê¸°ìš¸ê¸° í´ë¦¬í•‘ ì„ê³„ê°’\n",
    "    # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„\n",
    "    warmup_ratio=0.03,  # ì›Œë°ì—… ë‹¨ê³„ ë¹„ìœ¨\n",
    "    lr_scheduler_type=\"constant\",  # ì›Œë°ì—… í›„ í•™ìŠµë¥  ì¼ì •í•˜ê²Œ ìœ ì§€\n",
    "    # ë¡œê¹… ë° ì €ì¥\n",
    "    logging_steps=10,  # N ë‹¨ê³„ë§ˆë‹¤ ë©”íŠ¸ë¦­ ë¡œê¹…\n",
    "    save_strategy=\"epoch\",  # ì—í¬í¬ë§ˆë‹¤ ì²´í¬í¬ì¸íŠ¸ ì €ì¥\n",
    "    # ì •ë°€ë„ ì„¤ì •\n",
    "    bf16=True,  # bfloat16 ì •ë°€ë„ ì‚¬ìš©\n",
    "    # í†µí•© ì„¤ì •\n",
    "    push_to_hub=False,  # HuggingFace í—ˆë¸Œì— í‘¸ì‹œí•˜ì§€ ì•ŠìŒ\n",
    "    report_to=\"none\",  # ì™¸ë¶€ ë¡œê¹… ë¹„í™œì„±í™”\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cGhR7uFBouLl"
   },
   "source": [
    "ì´ì œ ëª¨ë¸ í›ˆë ¨ì„ ì‹œì‘í•˜ê¸° ìœ„í•´ `SFTTrainer`ë¥¼ ë§Œë“œëŠ” ë° í•„ìš”í•œ ëª¨ë“  êµ¬ì„± ìš”ì†Œë¥¼ ê°–ì¶”ì—ˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M00Har2douLl"
   },
   "outputs": [],
   "source": [
    "max_seq_length = 1512  # ëª¨ë¸ ë° ë°ì´í„° ì„¸íŠ¸ íŒ¨í‚¹ì„ ìœ„í•œ ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´\n",
    "\n",
    "# LoRA êµ¬ì„±ìœ¼ë¡œ SFTTrainer ìƒì„±\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    peft_config=peft_config,  # LoRA êµ¬ì„±\n",
    "    max_seq_length=max_seq_length,  # ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´\n",
    "    tokenizer=tokenizer,\n",
    "    packing=True,  # íš¨ìœ¨ì„±ì„ ìœ„í•´ ì…ë ¥ íŒ¨í‚¹ í™œì„±í™”\n",
    "    dataset_kwargs={\n",
    "        \"add_special_tokens\": False,  # í…œí”Œë¦¿ì—ì„œ ì²˜ë¦¬í•˜ëŠ” íŠ¹ìˆ˜ í† í°\n",
    "        \"append_concat_token\": False,  # ì¶”ê°€ êµ¬ë¶„ ê¸°í˜¸ í•„ìš” ì—†ìŒ\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQ_kRN24ouLl"
   },
   "source": [
    "`Trainer` ì¸ìŠ¤í„´ìŠ¤ì—ì„œ `train()` ë©”ì„œë“œë¥¼ í˜¸ì¶œí•˜ì—¬ ëª¨ë¸ í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ í›ˆë ¨ ë£¨í”„ê°€ ì‹œì‘ë˜ê³  3 ì—í¬í¬ ë™ì•ˆ ëª¨ë¸ì´ í›ˆë ¨ë©ë‹ˆë‹¤. PEFT ë°©ë²•ì„ ì‚¬ìš©í•˜ë¯€ë¡œ ì „ì²´ ëª¨ë¸ì´ ì•„ë‹Œ ì¡°ì •ëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ë§Œ ì €ì¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tq4nIYqKouLl"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "300e5dfbb4b54750b77324345c7591f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=72, training_loss=1.6402628521124523, metrics={'train_runtime': 195.2398, 'train_samples_per_second': 1.485, 'train_steps_per_second': 0.369, 'total_flos': 282267289092096.0, 'train_loss': 1.6402628521124523, 'epoch': 0.993103448275862})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# í›ˆë ¨ ì‹œì‘, ëª¨ë¸ì€ í—ˆë¸Œ ë° ì¶œë ¥ ë””ë ‰í„°ë¦¬ì— ìë™ìœ¼ë¡œ ì €ì¥ë©ë‹ˆë‹¤.\n",
    "trainer.train()\n",
    "\n",
    "# ëª¨ë¸ ì €ì¥\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y4HHSYYzouLl"
   },
   "source": [
    "15k ìƒ˜í”Œ ë°ì´í„° ì„¸íŠ¸ë¡œ 3 ì—í¬í¬ ë™ì•ˆ Flash Attentionìœ¼ë¡œ í›ˆë ¨í•˜ëŠ” ë° `g5.2xlarge`ì—ì„œ 4:14:36ì´ ê±¸ë ¸ìŠµë‹ˆë‹¤. ì¸ìŠ¤í„´ìŠ¤ ë¹„ìš©ì€ `1.21$/h`ì´ë¯€ë¡œ ì´ ë¹„ìš©ì€ ì•½ `5.3$`ì…ë‹ˆë‹¤.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C309KsXjouLl"
   },
   "source": [
    "### LoRA ì–´ëŒ‘í„°ë¥¼ ì›ë³¸ ëª¨ë¸ì— ë³‘í•©\n",
    "\n",
    "LoRAë¥¼ ì‚¬ìš©í•  ë•Œ ê¸°ë³¸ ëª¨ë¸ì€ ê³ ì •ëœ ìƒíƒœë¡œ ìœ ì§€í•˜ë©´ì„œ ì–´ëŒ‘í„° ê°€ì¤‘ì¹˜ë§Œ í›ˆë ¨í•©ë‹ˆë‹¤. í›ˆë ¨ ì¤‘ì—ëŠ” ì „ì²´ ëª¨ë¸ ë³µì‚¬ë³¸ì´ ì•„ë‹Œ ì´ëŸ¬í•œ ê²½ëŸ‰ ì–´ëŒ‘í„° ê°€ì¤‘ì¹˜(ì•½ 2-10MB)ë§Œ ì €ì¥í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë°°í¬ë¥¼ ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì€ ì´ìœ ë¡œ ì–´ëŒ‘í„°ë¥¼ ê¸°ë³¸ ëª¨ë¸ì— ë‹¤ì‹œ ë³‘í•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "1. **ê°„ì†Œí™”ëœ ë°°í¬**: ê¸°ë³¸ ëª¨ë¸ + ì–´ëŒ‘í„° ëŒ€ì‹  ë‹¨ì¼ ëª¨ë¸ íŒŒì¼\n",
    "2. **ì¶”ë¡  ì†ë„**: ì–´ëŒ‘í„° ê³„ì‚° ì˜¤ë²„í—¤ë“œ ì—†ìŒ\n",
    "3. **í”„ë ˆì„ì›Œí¬ í˜¸í™˜ì„±**: ì„œë¹™ í”„ë ˆì„ì›Œí¬ì™€ì˜ í˜¸í™˜ì„± í–¥ìƒ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import AutoPeftModelForCausalLM\n",
    "\n",
    "\n",
    "# CPUì—ì„œ PEFT ëª¨ë¸ ë¡œë“œ\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=args.output_dir,\n",
    "    torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True,\n",
    ")\n",
    "\n",
    "# LoRA ë° ê¸°ë³¸ ëª¨ë¸ ë³‘í•© ë° ì €ì¥\n",
    "merged_model = model.merge_and_unload()\n",
    "merged_model.save_pretrained(\n",
    "    args.output_dir, safe_serialization=True, max_shard_size=\"2GB\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-yO6E9quouLl"
   },
   "source": [
    "## 3. ëª¨ë¸ í…ŒìŠ¤íŠ¸ ë° ì¶”ë¡  ì‹¤í–‰\n",
    "\n",
    "í›ˆë ¨ì´ ëë‚˜ë©´ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤. ì›ë³¸ ë°ì´í„° ì„¸íŠ¸ì—ì„œ ë‹¤ë¥¸ ìƒ˜í”Œì„ ë¡œë“œí•˜ê³  ê°„ë‹¨í•œ ë£¨í”„ì™€ ì •í™•ë„ë¥¼ ë©”íŠ¸ë¦­ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ í•´ë‹¹ ìƒ˜í”Œì—ì„œ ëª¨ë¸ì„ í‰ê°€í•©ë‹ˆë‹¤.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color: lightblue; padding: 10px; border-radius: 5px; margin-bottom: 20px; color:black'>\n",
    "    <h2 style='margin: 0;color:blue'>ë³´ë„ˆìŠ¤ ì—°ìŠµ: LoRA ì–´ëŒ‘í„° ë¡œë“œ</h2>\n",
    "    <p>ì˜ˆì œ ë…¸íŠ¸ë¶ì—ì„œ ë°°ìš´ ë‚´ìš©ì„ ì‚¬ìš©í•˜ì—¬ í›ˆë ¨ëœ LoRA ì–´ëŒ‘í„°ë¥¼ ì¶”ë¡ ìš©ìœ¼ë¡œ ë¡œë“œí•©ë‹ˆë‹¤.</p> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "I5B494OdouLl"
   },
   "outputs": [],
   "source": [
    "# ë‹¤ì‹œ ë©”ëª¨ë¦¬ í•´ì œ\n",
    "del model\n",
    "del trainer\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P1UhohVdouLl"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "# PEFT ì–´ëŒ‘í„°ë¡œ ëª¨ë¸ ë¡œë“œ\n",
    "tokenizer = AutoTokenizer.from_pretrained(finetune_name)\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    finetune_name, device_map=\"auto\", torch_dtype=torch.float16\n",
    ")\n",
    "pipe = pipeline(\n",
    "    \"text-generation\", model=merged_model, tokenizer=tokenizer, device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "99uFDAuuouLl"
   },
   "source": [
    "ì¼ë¶€ í”„ë¡¬í”„íŠ¸ ìƒ˜í”Œì„ í…ŒìŠ¤íŠ¸í•˜ê³  ëª¨ë¸ ì„±ëŠ¥ì„ í™•ì¸í•´ ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "-shSmUbvouLl",
    "outputId": "16d97c61-3b31-4040-c780-3c4de75c3824"
   },
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"What is the capital of Germany? Explain why thats the case and if it was different in the past?\",\n",
    "    \"Write a Python function to calculate the factorial of a number.\",\n",
    "    \"A rectangular garden has a length of 25 feet and a width of 15 feet. If you want to build a fence around the entire garden, how many feet of fencing will you need?\",\n",
    "    \"What is the difference between a fruit and a vegetable? Give examples of each.\",\n",
    "]\n",
    "\n",
    "\n",
    "def test_inference(prompt):\n",
    "    prompt = pipe.tokenizer.apply_chat_template(\n",
    "        [{\"role\": \"user\", \"content\": prompt}],\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "    )\n",
    "    outputs = pipe(\n",
    "        prompt,\n",
    "    )\n",
    "    return outputs[0][\"generated_text\"][len(prompt) :].strip()\n",
    "\n",
    "\n",
    "for prompt in prompts:\n",
    "    print(f\"    prompt:\\n{prompt}\")\n",
    "    print(f\"    response:\\n{test_inference(prompt)}\")\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
