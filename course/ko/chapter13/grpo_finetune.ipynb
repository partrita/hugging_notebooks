{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GRPO로 LLM 미세 조정\n",
        "\n",
        "이 노트북은 `trl` 라이브러리를 사용하여 GRPO로 LLM을 미세 조정하는 방법을 보여줍니다.\n",
        "\n",
        "[Ben Burtenshaw](https://huggingface.co/burtenshaw)와 [Maxime Labonne](https://huggingface.co/mlabonne)이 만들었습니다.\n",
        "\n",
        "이것은 최소한의 예제입니다. 전체 예제는 [과정](https://huggingface.co/course/en/chapter12/1)의 GRPO 장을 참조하십시오.\n",
        "\n",
        "## 종속성 설치"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3IstgzN63QW"
      },
      "outputs": [],
      "source": [
        "!pip install -qqq datasets==3.2.0 transformers==4.47.1 trl==0.14.0 peft==0.14.0 accelerate==1.2.1 bitsandbytes==0.45.2 wandb==0.19.7 --progress-bar off\n",
        "!pip install -qqq flash-attn --no-build-isolation --progress-bar off"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 데이터 세트 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "5Y-X13wB7UP4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import wandb\n",
        "from datasets import load_dataset\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from trl import GRPOConfig, GRPOTrainer\n",
        "\n",
        "# Weights & Biases에 로그인\n",
        "wandb.login()\n",
        "\n",
        "# 데이터 세트 로드\n",
        "dataset = load_dataset(\"mlabonne/smoltldr\")\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 모델 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tLRvi5i-Qls"
      },
      "outputs": [],
      "source": [
        "# 모델 로드\n",
        "model_id = \"HuggingFaceTB/SmolLM-135M-Instruct\"\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=\"auto\",\n",
        "    device_map=\"auto\",\n",
        "    attn_implementation=\"flash_attention_2\",\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "# LoRA 로드\n",
        "lora_config = LoraConfig(\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=\"all-linear\",\n",
        ")\n",
        "model = get_peft_model(model, lora_config)\n",
        "print(model.print_trainable_parameters())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 보상 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "745L0RC6-XBT"
      },
      "outputs": [],
      "source": [
        "# 보상 함수\n",
        "def reward_len(completions, **kwargs):\n",
        "    return [-abs(50 - len(completion)) for completion in completions]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 훈련 인수 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 훈련 인수\n",
        "training_args = GRPOConfig(\n",
        "    output_dir=\"GRPO\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    gradient_accumulation_steps=2,\n",
        "    max_prompt_length=512,\n",
        "    max_completion_length=96,\n",
        "    num_generations=8,\n",
        "    optim=\"adamw_8bit\",\n",
        "    num_train_epochs=1,\n",
        "    bf16=True,\n",
        "    report_to=[\"wandb\"],\n",
        "    remove_unused_columns=False,\n",
        "    logging_steps=1,\n",
        ")\n",
        "\n",
        "# 트레이너\n",
        "trainer = GRPOTrainer(\n",
        "    model=model,\n",
        "    reward_funcs=[reward_len],\n",
        "    args=training_args,\n",
        "    train_dataset=dataset[\"train\"],\n",
        ")\n",
        "\n",
        "# 모델 훈련\n",
        "wandb.init(project=\"GRPO\")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 허브에 모델 푸시"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKHhpA4z-sRF"
      },
      "outputs": [],
      "source": [
        "# 모델 저장\n",
        "merged_model = trainer.model.merge_and_unload()\n",
        "merged_model.push_to_hub(\"<your-model-id>\", private=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 텍스트 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "# 고양이에 대한 긴 문서\n",
        "\n",
        "고양이(Felis catus)는 집고양이 또는 반려묘라고도 하며, 작고 길들여진 육식 포유류입니다. 고양잇과에서 유일하게 길들여진 종입니다.\n",
        "고고학과 유전학의 발전으로 고양이의 가축화는 기원전 7500년경 근동에서 일어났다는 것이 밝혀졌습니다.\n",
        "일반적으로 애완동물과 농장 고양이로 길러지지만, 인간과의 접촉을 피하는 야생 고양이로 자유롭게 돌아다니기도 합니다.\n",
        "인간에게는 동반자 관계와 해충을 죽이는 능력으로 가치가 있습니다. 수축 가능한 발톱은 쥐와 같은 작은 먹잇감을 죽이는 데 적합합니다.\n",
        "강하고 유연한 몸, 빠른 반사 신경, 날카로운 이빨을 가지고 있으며, 야간 시력과 후각이 잘 발달되어 있습니다.\n",
        "사회적인 종이지만, 단독 사냥꾼이자 박명박모성 포식자입니다. 고양이의 의사소통에는 야옹거리는 소리, 가르랑거리는 소리, 트릴링하는 소리, 하악질하는 소리, 으르렁거리는 소리, 끙끙거리는 소리와 같은 발성뿐만 아니라 몸짓 언어도 포함됩니다.\n",
        "인간의 귀에는 너무 희미하거나 너무 높은 주파수의 소리, 예를 들어 작은 포유류가 내는 소리를 들을 수 있습니다. 페로몬을 분비하고 감지합니다.\n",
        "\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": prompt},\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jbz8DYd-o7A"
      },
      "outputs": [],
      "source": [
        "# 텍스트 생성\n",
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=\"<your-model-id>\")\n",
        "\n",
        "## 또는 이전에 정의한 모델과 토크나이저 사용\n",
        "# generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "generate_kwargs = {\n",
        "    \"max_new_tokens\": 256,\n",
        "    \"do_sample\": True,\n",
        "    \"temperature\": 0.5,\n",
        "    \"min_p\": 0.1,\n",
        "}\n",
        "\n",
        "generated_text = generator(messages, generate_kwargs=generate_kwargs)\n",
        "\n",
        "print(generated_text)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
