{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì¡°ê±´ë¶€ ìƒì„±ì„ ìœ„í•œ ì ‘ë‘ì‚¬ íŠœë‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì ‘ë‘ì‚¬ íŠœë‹ì€ ì—°ì†ì ì¸ ì‘ì—…ë³„ ë²¡í„° ì‹œí€€ìŠ¤ë§Œ ì…ë ¥ ì‹œì‘ ë¶€ë¶„ ë˜ëŠ” *ì ‘ë‘ì‚¬*ì— ì²¨ë¶€ë˜ëŠ” ì¶”ê°€ ë°©ë²•ì…ë‹ˆë‹¤. ì ‘ë‘ì‚¬ ë§¤ê°œë³€ìˆ˜ë§Œ ìµœì í™”ë˜ê³  ëª¨ë¸ì˜ ëª¨ë“  ê³„ì¸µì—ì„œ ìˆ¨ê²¨ì§„ ìƒíƒœì— ì¶”ê°€ë©ë‹ˆë‹¤. ì…ë ¥ ì‹œí€€ìŠ¤ì˜ í† í°ì€ ì—¬ì „íˆ *ê°€ìƒ í† í°*ìœ¼ë¡œ ì ‘ë‘ì‚¬ì— ì£¼ì˜ë¥¼ ê¸°ìš¸ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê²°ê³¼ì ìœ¼ë¡œ ì ‘ë‘ì‚¬ íŠœë‹ì€ ì™„ì „íˆ ë¯¸ì„¸ ì¡°ì •ëœ ëª¨ë¸ë³´ë‹¤ 1000ë°° ì ì€ ë§¤ê°œë³€ìˆ˜ë¥¼ ì €ì¥í•˜ë¯€ë¡œ ë§ì€ ì‘ì—…ì— í•˜ë‚˜ì˜ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "<Tip>\n",
    "\n",
    "ğŸ’¡ ì ‘ë‘ì‚¬ íŠœë‹ì— ëŒ€í•´ ìì„¸íˆ ì•Œì•„ë³´ë ¤ë©´ [ì ‘ë‘ì‚¬ íŠœë‹: ìƒì„±ì„ ìœ„í•œ ì—°ì† í”„ë¡¬í”„íŠ¸ ìµœì í™”](https://arxiv.org/abs/2101.00190)ë¥¼ ì½ì–´ë³´ì„¸ìš”.\n",
    "\n",
    "</Tip>\n",
    "\n",
    "ì´ ê°€ì´ë“œì—ì„œëŠ” ì ‘ë‘ì‚¬ íŠœë‹ì„ ì ìš©í•˜ì—¬ [financial_phrasebank](https://huggingface.co/datasets/financial_phrasebank) ë°ì´í„° ì„¸íŠ¸ì˜ `sentences_allagree` í•˜ìœ„ ì§‘í•©ì—ì„œ [`t5-large`](https://huggingface.co/t5-large) ëª¨ë¸ì„ í›ˆë ¨í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
    "\n",
    "ì‹œì‘í•˜ê¸° ì „ì— í•„ìš”í•œ ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\n",
    "\n",
    "```bash\n",
    "!pip install -q peft transformers datasets\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì„¤ì •"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €, í…ìŠ¤íŠ¸ ë° ë ˆì´ë¸” ì—´, ì¼ë¶€ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì •ì˜í•˜ì—¬ ë‚˜ì¤‘ì— ë” ë¹¨ë¦¬ í›ˆë ¨ì„ ì‹œì‘í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ `TOKENIZERS_PARALLELSIM`ì„ `false`ë¡œ ì„¤ì •í•˜ì—¬ ê¸°ë³¸ì ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë³‘ë ¬ë¡œ ì²˜ë¦¬í•˜ëŠ” ë¹ ë¥¸ Rust ê¸°ë°˜ í† í¬ë‚˜ì´ì €ë¥¼ ë¹„í™œì„±í™”í•˜ì—¬ Pythonì—ì„œ ë‹¤ì¤‘ ì²˜ë¦¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, default_data_collator, get_linear_schedule_with_warmup\n",
    "from peft import get_peft_config, get_peft_model, get_peft_model_state_dict, PrefixTuningConfig, TaskType\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "device = \"cuda\"\n",
    "model_name_or_path = \"t5-large\"\n",
    "tokenizer_name_or_path = \"t5-large\"\n",
    "\n",
    "text_column = \"sentence\"\n",
    "label_column = \"text_label\"\n",
    "max_length = 128\n",
    "lr = 1e-2\n",
    "num_epochs = 5\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë°ì´í„° ì„¸íŠ¸ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ ê°€ì´ë“œì—ì„œëŠ” [`financial_phrasebank`](https://huggingface.co/datasets/financial_phrasebank) ë°ì´í„° ì„¸íŠ¸ì˜ `sentences_allagree` í•˜ìœ„ ì§‘í•©ì—ì„œ í›ˆë ¨í•©ë‹ˆë‹¤. ì´ ë°ì´í„° ì„¸íŠ¸ì—ëŠ” ê°ì •ë³„ë¡œ ë¶„ë¥˜ëœ ê¸ˆìœµ ë‰´ìŠ¤ê°€ í¬í•¨ë©ë‹ˆë‹¤.\n",
    "\n",
    "ğŸ¤— [ë°ì´í„° ì„¸íŠ¸](https://huggingface.co/docs/datasets/index) [train_test_split](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.train_test_split) í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ í›ˆë ¨ ë° ê²€ì¦ ë¶„í• ì„ ë§Œë“¤ê³  `label` ê°’ì„ ë” ì½ê¸° ì‰¬ìš´ `text_label`ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. ëª¨ë“  ë³€ê²½ ì‚¬í•­ì€ [map](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.map) í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"financial_phrasebank\", \"sentences_allagree\")\n",
    "dataset = dataset[\"train\"].train_test_split(test_size=0.1)\n",
    "dataset[\"validation\"] = dataset[\"test\"]\n",
    "del dataset[\"test\"]\n",
    "\n",
    "classes = dataset[\"train\"].features[\"label\"].names\n",
    "dataset = dataset.map(\n",
    "    lambda x: {\"text_label\": [classes[label] for label in x[\"label\"]]},\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    ")\n",
    "\n",
    "dataset[\"train\"][0]\n",
    "{\"sentence\": \"ì„¸ì „ ì´ìµì€ 490ë§Œ ìœ ë¡œì—ì„œ ê°ì†Œí•œ 400ë§Œ ìœ ë¡œì˜€ìŠµë‹ˆë‹¤.\", \"label\": 0, \"text_label\": \"negative\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë°ì´í„° ì„¸íŠ¸ ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í† í¬ë‚˜ì´ì €ë¥¼ ì´ˆê¸°í™”í•˜ê³  `model_inputs` ë° `labels`ë¥¼ íŒ¨ë”©í•˜ê³  ì˜ë¼ë‚´ëŠ” í•¨ìˆ˜ë¥¼ ë§Œë“­ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = examples[text_column]\n",
    "    targets = examples[label_column]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "    labels = tokenizer(targets, max_length=2, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "    labels = labels[\"input_ids\"]\n",
    "    labels[labels == tokenizer.pad_token_id] = -100\n",
    "    model_inputs[\"labels\"] = labels\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[map](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.map) í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ `preprocess_function`ì„ ë°ì´í„° ì„¸íŠ¸ì— ì ìš©í•©ë‹ˆë‹¤. ëª¨ë¸ì— ë” ì´ìƒ í•„ìš”í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì²˜ë¦¬ë˜ì§€ ì•Šì€ ì—´ì„ ì œê±°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_datasets = dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    "    load_from_cache_file=False,\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train` ë° `eval` ë°ì´í„° ì„¸íŠ¸ì—ì„œ [`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)ë¥¼ ë§Œë“­ë‹ˆë‹¤. ë°ì´í„° ì„¸íŠ¸ì˜ ìƒ˜í”Œì´ CPUì— ìˆëŠ” ê²½ìš° í›ˆë ¨ ì¤‘ GPUë¡œì˜ ë°ì´í„° ì „ì†¡ ì†ë„ë¥¼ ë†’ì´ë ¤ë©´ `pin_memory=True`ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = processed_datasets[\"train\"]\n",
    "eval_dataset = processed_datasets[\"validation\"]\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, shuffle=True, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True\n",
    ")\n",
    "eval_dataloader = DataLoader(eval_dataset, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ëª¨ë¸ í›ˆë ¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ ëª¨ë¸ì„ ì„¤ì •í•˜ê³  í›ˆë ¨ ì¤€ë¹„ê°€ ë˜ì—ˆëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. [PrefixTuningConfig](https://huggingface.co/docs/peft/main/en/package_reference/tuners#peft.PrefixTuningConfig)ì—ì„œ ì‘ì—…ì„ ì§€ì •í•˜ê³ , [AutoModelForSeq2SeqLM](https://huggingface.co/docs/transformers/main/en/model_doc/auto#transformers.AutoModelForSeq2SeqLM)ì—ì„œ ê¸°ë³¸ `t5-large` ëª¨ë¸ì„ ë§Œë“¤ê³ , ëª¨ë¸ê³¼ êµ¬ì„±ì„ [PeftModel](https://huggingface.co/docs/peft/main/en/package_reference/peft_model#peft.PeftModel)ë¡œ ë˜í•‘í•©ë‹ˆë‹¤. [PeftModel](https://huggingface.co/docs/peft/main/en/package_reference/peft_model#peft.PeftModel)ì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ì¸ì‡„í•˜ê³  ëª¨ë“  ëª¨ë¸ ë§¤ê°œë³€ìˆ˜ë¥¼ ì™„ì „íˆ í›ˆë ¨í•˜ëŠ” ê²ƒê³¼ ë¹„êµí•˜ì—¬ ì–¼ë§ˆë‚˜ íš¨ìœ¨ì ì¸ì§€ ììœ ë¡­ê²Œ í™•ì¸í•˜ì„¸ìš”!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = PrefixTuningConfig(task_type=TaskType.SEQ_2_SEQ_LM, inference_mode=False, num_virtual_tokens=20)\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path)\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()\n",
    "\"trainable params: 983040 || all params: 738651136 || trainable%: 0.13308583065659835\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì˜µí‹°ë§ˆì´ì €ì™€ í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "lr_scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=(len(train_dataloader) * num_epochs),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ëª¨ë¸ì„ GPUë¡œ ì˜®ê¸´ ë‹¤ìŒ í›ˆë ¨ ë£¨í”„ë¥¼ ì‘ì„±í•˜ì—¬ ì‹œì‘í•©ë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.detach().float()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    eval_preds = []\n",
    "    for step, batch in enumerate(tqdm(eval_dataloader)):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        eval_loss += loss.detach().float()\n",
    "        eval_preds.extend(\n",
    "            tokenizer.batch_decode(torch.argmax(outputs.logits, -1).detach().cpu().numpy(), skip_special_tokens=True)\n",
    "        )\n",
    "\n",
    "    eval_epoch_loss = eval_loss / len(eval_dataloader)\n",
    "    eval_ppl = torch.exp(eval_epoch_loss)\n",
    "    train_epoch_loss = total_loss / len(train_dataloader)\n",
    "    train_ppl = torch.exp(train_epoch_loss)\n",
    "    print(f\"{epoch=}: {train_ppl=} {train_epoch_loss=} {eval_ppl=} {eval_epoch_loss=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê²€ì¦ ì„¸íŠ¸ì—ì„œ ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ ì˜ ìˆ˜í–‰ë˜ëŠ”ì§€ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for pred, true in zip(eval_preds, dataset[\"validation\"][\"text_label\"]):\n",
    "    if pred.strip() == true.strip():\n",
    "        correct += 1\n",
    "    total += 1\n",
    "accuracy = correct / total * 100\n",
    "print(f\"{accuracy=} % on the evaluation dataset\")\n",
    "print(f\"{eval_preds[:10]=}\")\n",
    "print(f\"{dataset['validation']['text_label'][:10]=}\")\n",
    "\"accuracy=97.3568281938326 % on the evaluation dataset\"\n",
    "\"eval_preds[:10]=['neutral', 'positive', 'neutral', 'positive', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'neutral']\"\n",
    "\"dataset['validation']['text_label'][:10]=['neutral', 'positive', 'neutral', 'positive', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'neutral']\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ëª‡ ë¶„ ë§Œì— 97%ì˜ ì •í™•ë„, ê½¤ ì¢‹ìŠµë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ëª¨ë¸ ê³µìœ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì›í•˜ëŠ” ê²½ìš° Hubì—ì„œ ëª¨ë¸ì„ ì €ì¥í•˜ê³  ê³µìœ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Hugging Face ê³„ì •ì— ë¡œê·¸ì¸í•˜ê³  ë©”ì‹œì§€ê°€ í‘œì‹œë˜ë©´ í† í°ì„ ì…ë ¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[push_to_hub](https://huggingface.co/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.push_to_hub) í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ Hubì˜ íŠ¹ì • ëª¨ë¸ ë¦¬í¬ì§€í† ë¦¬ì— ëª¨ë¸ì„ ì—…ë¡œë“œí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model_id = \"your-name/t5-large_PREFIX_TUNING_SEQ2SEQ\"\n",
    "model.push_to_hub(\"your-name/t5-large_PREFIX_TUNING_SEQ2SEQ\", use_auth_token=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë¦¬í¬ì§€í† ë¦¬ì—ì„œ ëª¨ë¸ íŒŒì¼ í¬ê¸°ë¥¼ í™•ì¸í•˜ë©´ 3.93MBì— ë¶ˆê³¼í•˜ë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤! ğŸ¤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì¶”ë¡ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ëª¨ë¸ì´ Hubì— ì—…ë¡œë“œë˜ë©´ ëˆ„êµ¬ë‚˜ ì‰½ê²Œ ì¶”ë¡ ì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. êµ¬ì„±ê³¼ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "peft_model_id = \"stevhliu/t5-large_PREFIX_TUNING_SEQ2SEQ\"\n",
    "\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(config.base_model_name_or_path)\n",
    "model = PeftModel.from_pretrained(model, peft_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê¸ˆìœµ ë‰´ìŠ¤ì— ëŒ€í•œ ì¼ë¶€ í…ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì™€ í† í°í™”í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\n",
    "    \"ë¦¬íˆ¬ì•„ë‹ˆì•„ ë§¥ì£¼ ì‹œì¥ì€ 1ì›”ì— 1,441ë§Œ ë¦¬í„°ë¥¼ ê¸°ë¡í•˜ì—¬ ì „ë…„ ë™ê¸° ëŒ€ë¹„ 0.8% ì¦ê°€í–ˆìœ¼ë©°, ë¦¬íˆ¬ì•„ë‹ˆì•„ ì–‘ì¡°ì—…ì í˜‘íšŒëŠ” íšŒì›ì‚¬ì˜ ê²°ê³¼ë¥¼ ì¸ìš©í•˜ì—¬ ë³´ê³ í–ˆìŠµë‹ˆë‹¤.\",\n",
    "    return_tensors=\"pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ëª¨ë¸ì„ GPUì— ë†“ê³  ì˜ˆì¸¡ëœ í…ìŠ¤íŠ¸ ê°ì •ì„ *ìƒì„±*í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    outputs = model.generate(input_ids=inputs[\"input_ids\"], max_new_tokens=10)\n",
    "    print(tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True))\n",
    "[\"positive\"]"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
