{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets 설치\n",
    "! pip install datasets transformers\n",
    "# 마지막 릴리스 대신 소스에서 설치하려면 위 명령을 주석 처리하고 다음 명령의 주석 처리를 해제하십시오.\n",
    "# ! pip install git+https://github.com/huggingface/datasets.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 빠른 시작"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 빠른 시작은 코드를 직접 살펴보고 🤗 Datasets를 모델 학습 워크플로에 통합하는 방법을 보여주는 예제를 확인하려는 개발자를 위한 것입니다. 초보자인 경우 [튜토리얼](https://huggingface.co/docs/datasets/main/en/./tutorial)부터 시작하는 것이 좋습니다. 여기에서 더 자세한 소개를 확인할 수 있습니다.\n",
    "\n",
    "각 데이터셋은 고유하며 작업에 따라 일부 데이터셋은 학습을 위해 추가적인 준비 단계가 필요할 수 있습니다. 하지만 언제든지 🤗 Datasets 도구를 사용하여 데이터셋을 로드하고 처리할 수 있습니다. 가장 빠르고 쉬운 시작 방법은 [Hugging Face Hub](https://huggingface.co/datasets)에서 기존 데이터셋을 로드하는 것입니다. 다양한 작업에 걸쳐 수천 개의 데이터셋 중에서 선택할 수 있습니다. 작업하려는 데이터셋 유형을 선택하고 시작해 봅시다!\n",
    "\n",
    "<div class=\"mt-4\">\n",
    "  <div class=\"w-full flex flex-col space-y-4 md:space-y-0 md:grid md:grid-cols-3 md:gap-y-4 md:gap-x-5\">\n",
    "    <a\n",
    "      class=\"!no-underline border dark:border-gray-700 p-5 rounded-lg shadow hover:shadow-lg\"\n",
    "      href=\"#audio\"\n",
    "    >\n",
    "      <div class=\"w-full text-center bg-gradient-to-r from-violet-300 via-sky-400 to-green-500 rounded-lg py-1.5 font-semibold mb-5 text-white text-lg leading-relaxed\">\n",
    "        오디오\n",
    "      </div>\n",
    "      <p class=\"text-gray-700\">\n",
    "        오디오 데이터셋을 리샘플링하고 스피커가 어떤 은행 문제로 전화했는지 분류하는 모델을 준비합니다.\n",
    "      </p>\n",
    "    </a>\n",
    "    <a\n",
    "      class=\"!no-underline border dark:border-gray-700 p-5 rounded-lg shadow hover:shadow-lg\"\n",
    "      href=\"#vision\"\n",
    "    >\n",
    "      <div class=\"w-full text-center bg-gradient-to-r from-pink-400 via-purple-400 to-blue-500 rounded-lg py-1.5 font-semibold mb-5 text-white text-lg leading-relaxed\">\n",
    "        비전\n",
    "      </div>\n",
    "      <p class=\"text-gray-700\">\n",
    "        이미지 데이터셋에 데이터 증강을 적용하고 콩 식물의 질병을 진단하는 모델을 준비합니다.\n",
    "      </p>\n",
    "    </a>\n",
    "    <a\n",
    "      class=\"!no-underline border dark:border-gray-700 p-5 rounded-lg shadow hover:shadow-lg\"\n",
    "      href=\"#nlp\"\n",
    "    >\n",
    "      <div class=\"w-full text-center bg-gradient-to-r from-orange-300 via-red-400 to-violet-500 rounded-lg py-1.5 font-semibold mb-5 text-white text-lg leading-relaxed\">\n",
    "        NLP\n",
    "      </div>\n",
    "      <p class=\"text-gray-700\">\n",
    "        데이터셋을 토큰화하고 두 문장이 같은 의미인지 판단하는 모델을 준비합니다.\n",
    "      </p>\n",
    "    </a>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<Tip>\n",
    "\n",
    "Hugging Face 과정의 [5장](https://huggingface.co/course/chapter5/1?fw=pt)에서 원격 또는 로컬 데이터셋 로드, 데이터셋 정리 도구, 나만의 데이터셋 만들기 등 다른 중요한 주제에 대해 자세히 알아보세요.\n",
    "\n",
    "</Tip>\n",
    "\n",
    "🤗 Datasets를 설치하여 시작합니다.\n",
    "\n",
    "```bash\n",
    "pip install datasets\n",
    "```\n",
    "\n",
    "🤗 Datasets는 오디오 및 이미지 데이터 형식도 지원합니다.\n",
    "\n",
    "- 오디오 데이터셋으로 작업하려면 [Audio](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Audio) 기능을 설치합니다.\n",
    "\n",
    "  ```bash\n",
    "  pip install datasets[audio]\n",
    "  ```\n",
    "\n",
    "- 이미지 데이터셋으로 작업하려면 [Image](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Image) 기능을 설치합니다.\n",
    "\n",
    "  ```bash\n",
    "  pip install datasets[vision]\n",
    "  ```\n",
    "\n",
    "🤗 Datasets 외에도 선호하는 머신러닝 프레임워크가 설치되어 있는지 확인하십시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 오디오"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오디오 데이터셋은 텍스트 데이터셋과 마찬가지로 로드됩니다. 그러나 오디오 데이터셋은 약간 다르게 전처리됩니다. 토크나이저 대신 [특성 추출기](https://huggingface.co/docs/transformers/main_classes/feature_extractor#feature-extractor)가 필요합니다. 오디오 입력은 사용 중인 사전 훈련된 모델의 샘플링 속도와 일치하도록 샘플링 속도를 리샘플링해야 할 수도 있습니다. 이 빠른 시작에서는 [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14) 데이터셋을 준비하여 모델이 고객이 겪고 있는 은행 문제를 훈련하고 분류하도록 합니다.\n",
    "\n",
    "**1**. 데이터셋 이름, 데이터셋 구성(모든 데이터셋에 구성이 있는 것은 아님) 및 데이터셋 분할을 [load_dataset()](https://huggingface.co/docs/datasets/main/en/package_reference/loading_methods#datasets.load_dataset) 함수에 제공하여 MInDS-14 데이터셋을 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "\n",
    "dataset = load_dataset(\"PolyAI/minds14\", \"en-US\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2**. 다음으로 [🤗 Transformers](https://huggingface.co/transformers/) 라이브러리에서 사전 훈련된 [Wav2Vec2](https://huggingface.co/facebook/wav2vec2-base) 모델과 해당 특성 추출기를 로드합니다. 일부 가중치가 초기화되지 않았다는 경고가 모델을 로드한 후 표시되는 것은 지극히 정상입니다. 다른 작업으로 훈련하기 위해 이 모델 체크포인트를 로드하고 있으므로 예상되는 현상입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForAudioClassification, AutoFeatureExtractor\n",
    "\n",
    "model = AutoModelForAudioClassification.from_pretrained(\"facebook/wav2vec2-base\")\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"facebook/wav2vec2-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3**. [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14) 데이터셋 카드에는 샘플링 속도가 8kHz로 표시되어 있지만 Wav2Vec2 모델은 16kHz의 샘플링 속도로 사전 훈련되었습니다. 모델의 샘플링 속도와 일치하도록 [cast_column()](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.cast_column) 함수와 [Audio](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Audio) 기능을 사용하여 `audio` 열을 업샘플링해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<datasets.features._torchcodec.AudioDecoder object at 0x11642b6a0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "dataset[0][\"audio\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4**. 특성 추출기를 사용하여 오디오 `array`를 전처리하고 시퀀스를 깔끔한 직사각형 텐서로 자르고 채우는 함수를 만듭니다. 가장 중요한 점은 실제 음성 신호인 `array`가 모델 입력이므로 특성 추출기에서 오디오 `array`를 호출해야 한다는 것입니다.\n",
    "\n",
    "전처리 함수가 있으면 [map()](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.map) 함수를 사용하여 데이터셋의 예제 배치에 함수를 적용하여 처리 속도를 높입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    audio_arrays = [x.get_all_samples().data for x in examples[\"audio\"]]\n",
    "    inputs = feature_extractor(\n",
    "        audio_arrays,\n",
    "        sampling_rate=16000,\n",
    "        padding=True,\n",
    "        max_length=100000,\n",
    "        truncation=True,\n",
    "    )\n",
    "    return inputs\n",
    "\n",
    "dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5**. [rename_column()](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.rename_column) 함수를 사용하여 `intent_class` 열의 이름을 [Wav2Vec2ForSequenceClassification](https://huggingface.co/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification)에서 예상되는 입력 이름인 `labels`로 바꿉니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.rename_column(\"intent_class\", \"labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6**. 사용 중인 머신러닝 프레임워크에 따라 데이터셋 형식을 설정합니다.\n",
    "\n",
    "\n",
    "🤗 Transformers의 [prepare_tf_dataset](https://huggingface.co/docs/transformers/main/en/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset) 메서드를 사용하여 데이터셋을 TensorFlow와 호환되도록 준비하고 모델을 훈련/미세 조정할 준비를 합니다. 이 메서드는 HuggingFace [Dataset](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset)을 조합 및 배치 기능이 있는 `tf.data.Dataset`으로 래핑하므로 추가 수정 없이 `fit()`과 같은 Keras 메서드에 직접 전달할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf_dataset = model.prepare_tf_dataset(\n",
    "    dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7**. 머신러닝 프레임워크로 훈련을 시작하세요! 오디오 데이터셋에서 모델을 훈련하는 방법에 대한 엔드투엔드 예제는 🤗 Transformers [오디오 분류 가이드](https://huggingface.co/docs/transformers/tasks/audio_classification)를 확인하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 비전"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 데이터셋은 텍스트 데이터셋과 마찬가지로 로드됩니다. 그러나 토크나이저 대신 데이터셋을 전처리하려면 [특성 추출기](https://huggingface.co/docs/transformers/main_classes/feature_extractor#feature-extractor)가 필요합니다. 이미지에 데이터 증강을 적용하는 것은 모델이 과적합에 더 강건하도록 만들기 위해 컴퓨터 비전에서 일반적입니다. 원하는 데이터 증강 라이브러리를 자유롭게 사용한 다음 🤗 Datasets를 사용하여 증강을 적용할 수 있습니다. 이 빠른 시작에서는 [Beans](https://huggingface.co/datasets/beans) 데이터셋을 로드하고 모델이 잎 이미지에서 질병을 식별하도록 훈련할 준비를 합니다.\n",
    "\n",
    "**1**. 데이터셋 이름과 데이터셋 분할을 [load_dataset()](https://huggingface.co/docs/datasets/main/en/package_reference/loading_methods#datasets.load_dataset) 함수에 제공하여 Beans 데이터셋을 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Image\n",
    "\n",
    "dataset = load_dataset(\"AI-Lab-Makerere/beans\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대부분의 이미지 모델은 RBG 이미지로 작동합니다. 데이터셋에 다른 모드의 이미지가 포함되어 있는 경우 [cast_column()](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.cast_column) 함수를 사용하여 모드를 RGB로 설정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.cast_column(\"image\", Image(mode=\"RGB\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beans 데이터셋에는 RGB 이미지만 포함되어 있으므로 이 단계는 여기에서 필요하지 않습니다.\n",
    "\n",
    "**2**. 이제 원하는 라이브러리([Albumentations](https://albumentations.ai/), [imgaug](https://imgaug.readthedocs.io/en/latest/), [Kornia](https://kornia.readthedocs.io/en/latest/))를 사용하여 일부 데이터 증강을 추가할 수 있습니다. 여기서는 [torchvision](https://pytorch.org/vision/stable/transforms.html)을 사용하여 이미지의 색상 속성을 무작위로 변경합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose, ColorJitter, ToTensor\n",
    "\n",
    "jitter = Compose(\n",
    "    [ColorJitter(brightness=0.5, hue=0.5), ToTensor()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3**. 변환을 데이터셋에 적용하고 모델 입력인 `pixel_values`를 생성하는 함수를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforms(examples):\n",
    "    examples[\"pixel_values\"] = [jitter(image.convert(\"RGB\")) for image in examples[\"image\"]]\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4**. [with_transform()](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.with_transform) 함수를 사용하여 즉시 데이터 증강을 적용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.with_transform(transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5**. 사용 중인 머신러닝 프레임워크에 따라 데이터셋 형식을 설정합니다.\n",
    "\n",
    "\n",
    "🤗 Transformers의 [prepare_tf_dataset](https://huggingface.co/docs/transformers/main/en/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset) 메서드를 사용하여 데이터셋을 TensorFlow와 호환되도록 준비하고 모델을 훈련/미세 조정할 준비를 합니다. 이 메서드는 HuggingFace [Dataset](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset)을 조합 및 배치 기능이 있는 `tf.data.Dataset`으로 래핑하므로 추가 수정 없이 `fit()`과 같은 Keras 메서드에 직접 전달할 수 있습니다.\n",
    "\n",
    "시작하기 전에 `albumentations` 및 `cv2`의 최신 버전이 설치되어 있는지 확인하십시오.\n",
    "\n",
    "```bash\n",
    "pip install -U albumentations opencv-python\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations\n",
    "import numpy as np\n",
    "\n",
    "transform = albumentations.Compose([\n",
    "    albumentations.RandomCrop(width=256, height=256),\n",
    "    albumentations.HorizontalFlip(p=0.5),\n",
    "    albumentations.RandomBrightnessContrast(p=0.2),\n",
    "])\n",
    "\n",
    "def transforms(examples):\n",
    "    examples[\"pixel_values\"] = [\n",
    "        transform(image=np.array(image))[\"image\"] for image in examples[\"image\"]\n",
    "    ]\n",
    "    return examples\n",
    "\n",
    "dataset.set_transform(transforms)\n",
    "tf_dataset = model.prepare_tf_dataset(\n",
    "    dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6**. 머신러닝 프레임워크로 훈련을 시작하세요! 이미지 데이터셋에서 모델을 훈련하는 방법에 대한 엔드투엔드 예제는 🤗 Transformers [이미지 분류 가이드](https://huggingface.co/docs/transformers/tasks/image_classification)를 확인하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텍스트는 [토크나이저](https://huggingface.co/docs/transformers/main_classes/tokenizer)에 의해 개별 토큰으로 토큰화되어야 합니다. 빠른 시작을 위해 [Microsoft Research Paraphrase Corpus (MRPC)](https://huggingface.co/datasets/glue/viewer/mrpc) 훈련 데이터셋을 로드하여 두 문장이 같은 의미인지 판단하는 모델을 훈련합니다.\n",
    "\n",
    "**1**. 데이터셋 이름, 데이터셋 구성(모든 데이터셋에 구성이 있는 것은 아님) 및 데이터셋 분할을 [load_dataset()](https://huggingface.co/docs/datasets/main/en/package_reference/loading_methods#datasets.load_dataset) 함수에 제공하여 MRPC 데이터셋을 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"nyu-mll/glue\", \"mrpc\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2**. 다음으로 [🤗 Transformers](https://huggingface.co/transformers/) 라이브러리에서 사전 훈련된 [BERT](https://huggingface.co/bert-base-uncased) 모델과 해당 토크나이저를 로드합니다. 일부 가중치가 초기화되지 않았다는 경고가 모델을 로드한 후 표시되는 것은 지극히 정상입니다. 다른 작업으로 훈련하기 위해 이 모델 체크포인트를 로드하고 있으므로 예상되는 현상입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===PT-TF-SPLIT==="
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3**. 데이터셋을 토큰화하는 함수를 만들고 텍스트를 깔끔한 직사각형 텐서로 자르고 채워야 합니다. 토크나이저는 데이터셋에 `input_ids`, `token_type_ids` 및 `attention_mask`라는 세 개의 새 열을 생성합니다. 이것이 모델 입력입니다.\n",
    "\n",
    "[map()](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.map) 함수를 사용하여 데이터셋의 예제 배치에 토큰화 함수를 적용하여 처리 속도를 높입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .',\n",
       "'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .',\n",
       "'label': 1,\n",
       "'idx': 0,\n",
       "'input_ids': [  101,  7277,  2180,  5303,  4806,  1117,  1711,   117,  2292, 1119,  1270,   107,  1103,  7737,   107,   117,  1104,  9938, 4267, 12223, 21811,  1117,  2554,   119,   102, 11336,  6732, 3384,  1106,  1140,  1112,  1178,   107,  1103,  7737,   107, 117,  7277,  2180,  5303,  4806,  1117,  1711,  1104,  9938, 4267, 12223, 21811,  1117,  2554,   119,   102, 0, 0, ...],\n",
       "'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, ...],\n",
       "'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, ...]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode(examples):\n",
    "    return tokenizer(examples[\"sentence1\"], examples[\"sentence2\"], truncation=True, padding=\"max_length\")\n",
    "\n",
    "dataset = dataset.map(encode, batched=True)\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4**. [BertForSequenceClassification](https://huggingface.co/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification)에서 예상되는 입력 이름인 `labels`로 `label` 열의 이름을 바꿉니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda examples: {\"labels\": examples[\"label\"]}, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5**. 사용 중인 머신러닝 프레임워크에 따라 데이터셋 형식을 설정합니다.\n",
    "\n",
    "\n",
    "🤗 Transformers의 [prepare_tf_dataset](https://huggingface.co/docs/transformers/main/en/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset) 메서드를 사용하여 데이터셋을 TensorFlow와 호환되도록 준비하고 모델을 훈련/미세 조정할 준비를 합니다. 이 메서드는 HuggingFace [Dataset](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset)을 조합 및 배치 기능이 있는 `tf.data.Dataset`으로 래핑하므로 추가 수정 없이 `fit()`과 같은 Keras 메서드에 직접 전달할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf_dataset = model.prepare_tf_dataset(\n",
    "    dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6**. 머신러닝 프레임워크로 훈련을 시작하세요! 텍스트 데이터셋에서 모델을 훈련하는 방법에 대한 엔드투엔드 예제는 🤗 Transformers [텍스트 분류 가이드](https://huggingface.co/docs/transformers/tasks/sequence_classification)를 확인하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다음 단계는 무엇인가요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이것으로 🤗 Datasets 빠른 시작을 마칩니다! 단일 함수로 모든 텍스트, 오디오 또는 이미지 데이터셋을 로드하고 모델 훈련을 위해 준비할 수 있습니다.\n",
    "\n",
    "다음 단계로 [방법 가이드](https://huggingface.co/docs/datasets/main/en/./how_to)를 살펴보고 다양한 데이터셋 형식 로드, 레이블 정렬, 대규모 데이터셋 스트리밍과 같은 보다 구체적인 작업을 수행하는 방법을 알아보세요. 🤗 Datasets 핵심 개념에 대해 더 자세히 알고 싶다면 커피 한 잔을 들고 [개념 가이드](https://huggingface.co/docs/datasets/main/en/./about_arrow)를 읽어보세요!"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}

[end of datasets_doc/en/tensorflow/quickstart.ipynb]
