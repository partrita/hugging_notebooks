{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ë¶„ë¥˜ í—¤ë“œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ëª¨ë“  ğŸ¤— SetFit ëª¨ë¸ì€ [SentenceTransformer](https://sbert.net/) ì„ë² ë”© ë³¸ë¬¸ê³¼ ë¶„ë¥˜ í—¤ë“œì˜ ë‘ ë¶€ë¶„ìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. \n",
    "\n",
    "ì´ ê°€ì´ë“œì—ì„œëŠ” ë‹¤ìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
    "* ë‚´ì¥ ë¡œì§€ìŠ¤í‹± íšŒê·€ ë¶„ë¥˜ í—¤ë“œ\n",
    "* ë‚´ì¥ ë¯¸ë¶„ ê°€ëŠ¥ ë¶„ë¥˜ í—¤ë“œ\n",
    "* ì‚¬ìš©ì ì§€ì • ë¶„ë¥˜ í—¤ë“œì˜ ìš”êµ¬ ì‚¬í•­"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë¡œì§€ìŠ¤í‹± íšŒê·€ ë¶„ë¥˜ í—¤ë“œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ìƒˆë¡œìš´ SetFit ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ë©´ ê¸°ë³¸ì ìœ¼ë¡œ [scikit-learn ë¡œì§€ìŠ¤í‹± íšŒê·€](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) í—¤ë“œê°€ ì„ íƒë©ë‹ˆë‹¤. ì´ëŠ” ë¯¸ì„¸ ì¡°ì •ëœ ë¬¸ì¥ ë³€í™˜ê¸° ë³¸ë¬¸ ìœ„ì— ì ìš©ë  ë•Œ ë§¤ìš° íš¨ê³¼ì ì¸ ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìœ¼ë©° ê¶Œì¥ë˜ëŠ” ë¶„ë¥˜ í—¤ë“œë¡œ ë‚¨ì•„ ìˆìŠµë‹ˆë‹¤. ë¡œì§€ìŠ¤í‹± íšŒê·€ í—¤ë“œë¡œ ìƒˆ SetFit ëª¨ë¸ì„ ì´ˆê¸°í™”í•˜ëŠ” ê²ƒì€ ê°„ë‹¨í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from setfit import SetFitModel\n",
    "\n",
    "model = SetFitModel.from_pretrained(\"BAAI/bge-small-en-v1.5\")\n",
    "model.model_head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë¡œì§€ìŠ¤í‹± íšŒê·€ í—¤ë“œ(ë˜ëŠ” ë‹¤ë¥¸ í—¤ë“œ)ë¥¼ ì¶”ê°€ ë§¤ê°œë³€ìˆ˜ë¡œ ì´ˆê¸°í™”í•˜ë ¤ë©´ `SetFitModel.from_pretrained()`ì—ì„œ `head_params` ì¸ìˆ˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=300, solver='liblinear')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from setfit import SetFitModel\n",
    "\n",
    "model = SetFitModel.from_pretrained(\"BAAI/bge-small-en-v1.5\", head_params={\"solver\": \"liblinear\", \"max_iter\": 300})\n",
    "model.model_head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë¯¸ë¶„ ê°€ëŠ¥ ë¶„ë¥˜ í—¤ë“œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SetFitì€ ë˜í•œ ë…ì ì ìœ¼ë¡œ `torch` ë¶„ë¥˜ í—¤ë“œì¸ [SetFitHead](https://huggingface.co/docs/setfit/main/en/reference/main#setfit.SetFitHead)ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì„ í˜• ê³„ì¸µì„ ì‚¬ìš©í•˜ì—¬ ì„ë² ë”©ì„ í´ë˜ìŠ¤ì— ë§¤í•‘í•©ë‹ˆë‹¤. `SetFitModel.from_pretrained()`ì—ì„œ `use_differentiable_head` ì¸ìˆ˜ë¥¼ `True`ë¡œ ì„¤ì •í•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SetFitHead({'in_features': 384, 'out_features': 2, 'temperature': 1.0, 'bias': True, 'device': 'cuda'})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from setfit import SetFitModel\n",
    "\n",
    "model = SetFitModel.from_pretrained(\"BAAI/bge-small-en-v1.5\", use_differentiable_head=True)\n",
    "model.model_head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê¸°ë³¸ì ìœ¼ë¡œ ì´ì§„ ë¶„ë¥˜ë¥¼ ê°€ì •í•©ë‹ˆë‹¤. ì´ë¥¼ ë³€ê²½í•˜ë ¤ë©´ `head_params`ë¥¼ í†µí•´ `out_features`ë¥¼ ì‚¬ìš© ì¤‘ì¸ í´ë˜ìŠ¤ ìˆ˜ë¡œ ì„¤ì •í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SetFitHead({'in_features': 384, 'out_features': 5, 'temperature': 1.0, 'bias': True, 'device': 'cuda'})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from setfit import SetFitModel\n",
    "\n",
    "model = SetFitModel.from_pretrained(\"BAAI/bge-small-en-v1.5\", use_differentiable_head=True, head_params={\"out_features\": 5})\n",
    "model.model_head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Tip warning={true}>\n",
    "\n",
    "ê¸°ë³¸ ë¡œì§€ìŠ¤í‹± íšŒê·€ í—¤ë“œì™€ ë‹¬ë¦¬ ë¯¸ë¶„ ê°€ëŠ¥ ë¶„ë¥˜ í—¤ë“œëŠ” ë‹¤ìŒ ë²”ìœ„ì˜ ì •ìˆ˜ ë ˆì´ë¸”ë§Œ ì§€ì›í•©ë‹ˆë‹¤. `[0, num_classes)`.\n",
    "\n",
    "</Tip>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¯¸ë¶„ ê°€ëŠ¥ ë¶„ë¥˜ í—¤ë“œë¡œ í›ˆë ¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[SetFitHead](https://huggingface.co/docs/setfit/main/en/reference/main#setfit.SetFitHead)ë¥¼ ì‚¬ìš©í•˜ë©´ sklearn ê¸°ë°˜ í—¤ë“œì™€ í•¨ê»˜ ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” ìƒˆë¡œìš´ [TrainingArguments](https://huggingface.co/docs/setfit/main/en/reference/trainer#setfit.TrainingArguments)ê°€ ì ê¸ˆ í•´ì œë©ë‹ˆë‹¤. SetFitìœ¼ë¡œ í›ˆë ¨í•˜ëŠ” ê²ƒì€ ë‚´ë¶€ì ìœ¼ë¡œ **ì„ë² ë”© ë¯¸ì„¸ ì¡°ì •**ê³¼ **ë¶„ë¥˜ í—¤ë“œ í›ˆë ¨**ì˜ ë‘ ë‹¨ê³„ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. ê²°ê³¼ì ìœ¼ë¡œ ì¼ë¶€ í›ˆë ¨ ì¸ìˆ˜ëŠ” íŠœí”Œì¼ ìˆ˜ ìˆìœ¼ë©°, ë‘ ê°’ì€ ê°ê° ë‘ ë‹¨ê³„ì— ì‚¬ìš©ë©ë‹ˆë‹¤. ì´ëŸ¬í•œ ê²½ìš° ëŒ€ë¶€ë¶„ ë¶„ë¥˜ í—¤ë“œê°€ ë¯¸ë¶„ ê°€ëŠ¥í•´ì•¼ ë‘ ë²ˆì§¸ ê°’ì´ ì‚¬ìš©ë©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´:\n",
    "\n",
    "* **batch_size**: (`Union[int, Tuple[int, int]]`, ê¸°ë³¸ê°’: `(16, 2)`) - íŠœí”Œì˜ ë‘ ë²ˆì§¸ ê°’ì€ ë¯¸ë¶„ ê°€ëŠ¥ SetFitHeadë¥¼ í›ˆë ¨í•  ë•Œ ë°°ì¹˜ í¬ê¸°ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.\n",
    "* **num_epochs**: (`Union[int, Tuple[int, int]]`, ê¸°ë³¸ê°’: `(1, 16)`) - íŠœí”Œì˜ ë‘ ë²ˆì§¸ ê°’ì€ ë¯¸ë¶„ ê°€ëŠ¥ SetFitHeadë¥¼ í›ˆë ¨í•  ë•Œ ì—í¬í¬ ìˆ˜ë¥¼ ê²°ì •í•©ë‹ˆë‹¤. ì‹¤ì œë¡œ `num_epochs`ëŠ” ì¼ë°˜ì ìœ¼ë¡œ ë¶„ë¥˜ í—¤ë“œ í›ˆë ¨ì— ë” í½ë‹ˆë‹¤. ì—¬ê¸°ì—ëŠ” ë‘ ê°€ì§€ ì´ìœ ê°€ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "    1. ì´ í›ˆë ¨ ë‹¨ê³„ì—ì„œëŠ” ëŒ€ì¡° ìŒìœ¼ë¡œ í›ˆë ¨í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì„ë² ë”© ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•  ë•Œì™€ ë‹¬ë¦¬ ë ˆì´ë¸”ì´ ì§€ì •ëœ ê° í›ˆë ¨ í…ìŠ¤íŠ¸ì— ëŒ€í•´ í•˜ë‚˜ì˜ í›ˆë ¨ ìƒ˜í”Œë§Œ ì–»ìŠµë‹ˆë‹¤.\n",
    "    2. ì´ í›ˆë ¨ ë‹¨ê³„ì—ëŠ” ì´ë¯¸ ìœ ëŠ¥í•œ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì²˜ìŒë¶€í„° ë¶„ë¥˜ê¸°ë¥¼ í›ˆë ¨í•˜ëŠ” ê²ƒì´ í¬í•¨ë©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ ë” ë§ì€ í›ˆë ¨ ë‹¨ê³„ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "* **end_to_end**: (`bool`, ê¸°ë³¸ê°’: `False`) - `True`ì´ë©´ ë¶„ë¥˜ê¸° í›ˆë ¨ ë‹¨ê³„ì—ì„œ ì „ì²´ ëª¨ë¸ì„ ì¢…ë‹¨ ê°„ìœ¼ë¡œ í›ˆë ¨í•©ë‹ˆë‹¤. ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ Sentence Transformer ë³¸ë¬¸ì„ ê³ ì •í•˜ê³  í—¤ë“œë§Œ í›ˆë ¨í•©ë‹ˆë‹¤.\n",
    "* **body_learning_rate**: (`Union[float, Tuple[float, float]]`, ê¸°ë³¸ê°’: `(2e-5, 1e-5)`) - íŠœí”Œì˜ ë‘ ë²ˆì§¸ ê°’ì€ ë¶„ë¥˜ê¸° í›ˆë ¨ ë‹¨ê³„ì—ì„œ Sentence Transformer ë³¸ë¬¸ì˜ í•™ìŠµë¥ ì„ ê²°ì •í•©ë‹ˆë‹¤. `end_to_end`ê°€ `True`ì¸ ê²½ìš°ì—ë§Œ ê´€ë ¨ì´ ìˆìŠµë‹ˆë‹¤. ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ë¶„ë¥˜ê¸°ë¥¼ í›ˆë ¨í•  ë•Œ Sentence Transformer ë³¸ë¬¸ì´ ê³ ì •ë©ë‹ˆë‹¤.\n",
    "* **head_learning_rate** (`float`, ê¸°ë³¸ê°’: `1e-2`) - ì´ ê°’ì€ ë¶„ë¥˜ê¸° í›ˆë ¨ ë‹¨ê³„ì—ì„œ ë¯¸ë¶„ ê°€ëŠ¥ í—¤ë“œì˜ í•™ìŠµë¥ ì„ ê²°ì •í•©ë‹ˆë‹¤. ë¯¸ë¶„ ê°€ëŠ¥ í—¤ë“œê°€ ì‚¬ìš©ë˜ëŠ” ê²½ìš°ì—ë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "* **l2_weight** (`float`, *ì„ íƒ ì‚¬í•­*) - ëª¨ë¸ ë³¸ë¬¸ê³¼ í—¤ë“œ ëª¨ë‘ì— ëŒ€í•œ ì„ íƒì  l2 ê°€ì¤‘ì¹˜ë¡œ, ë¯¸ë¶„ ê°€ëŠ¥ í—¤ë“œê°€ ì‚¬ìš©ë˜ëŠ” ê²½ìš°ì—ë§Œ ë¶„ë¥˜ê¸° í›ˆë ¨ ë‹¨ê³„ì—ì„œ `AdamW` ì˜µí‹°ë§ˆì´ì €ì— ì „ë‹¬ë©ë‹ˆë‹¤.\n",
    "\n",
    "ì˜ˆë¥¼ ë“¤ì–´ ë¯¸ë¶„ ê°€ëŠ¥ ë¶„ë¥˜ í—¤ë“œë¥¼ ì‚¬ìš©í•˜ëŠ” ì „ì²´ í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setfit import SetFitModel, Trainer, TrainingArguments, sample_dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "# ìƒˆë¡œìš´ SetFit ëª¨ë¸ ì´ˆê¸°í™”\n",
    "model = SetFitModel.from_pretrained(\"BAAI/bge-small-en-v1.5\", use_differentiable_head=True, head_params={\"out_features\": 2})\n",
    "\n",
    "# ë°ì´í„°ì…‹ ì¤€ë¹„\n",
    "dataset = load_dataset(\"SetFit/sst2\")\n",
    "train_dataset = sample_dataset(dataset[\"train\"], label_column=\"label\", num_samples=32)\n",
    "test_dataset = dataset[\"test\"]\n",
    "\n",
    "# í›ˆë ¨ ì¸ìˆ˜ ì¤€ë¹„\n",
    "args = TrainingArguments(\n",
    "    batch_size=(32, 16),\n",
    "    num_epochs=(3, 8),\n",
    "    end_to_end=True,\n",
    "    body_learning_rate=(2e-5, 5e-6),\n",
    "    head_learning_rate=2e-3,\n",
    "    l2_weight=0.01,\n",
    ")\n",
    "\n",
    "# íŠ¸ë ˆì´ë„ˆ ì¤€ë¹„\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    ")\n",
    "trainer.train()\n",
    "# ***** í›ˆë ¨ ì‹¤í–‰ ì¤‘ *****\n",
    "#   ì˜ˆì œ ìˆ˜ = 66\n",
    "#   ì—í¬í¬ ìˆ˜ = 3\n",
    "#   ì´ ìµœì í™” ë‹¨ê³„ = 198\n",
    "#   ì´ í›ˆë ¨ ë°°ì¹˜ í¬ê¸° = 3\n",
    "# {'embedding_loss': 0.2204, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.02}                                                                                 \n",
    "# {'embedding_loss': 0.0058, 'learning_rate': 1.662921348314607e-05, 'epoch': 0.76}                                                                                  \n",
    "# {'embedding_loss': 0.0026, 'learning_rate': 1.101123595505618e-05, 'epoch': 1.52}                                                                                  \n",
    "# {'embedding_loss': 0.0022, 'learning_rate': 5.393258426966292e-06, 'epoch': 2.27}                                                                                  \n",
    "# {'train_runtime': 36.6756, 'train_samples_per_second': 172.758, 'train_steps_per_second': 5.399, 'epoch': 3.0}                                                     \n",
    "# 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 198/198 [00:30<00:00,  6.45it/s] \n",
    "# `max_length`ëŠ” `None`ì…ë‹ˆë‹¤. í˜„ì¬ ëª¨ë¸ ë³¸ë¬¸ì— ë”°ë¼ í—ˆìš©ë˜ëŠ” ìµœëŒ€ ê¸¸ì´ ì‚¬ìš©: 512.\n",
    "# ì—í¬í¬: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:07<00:00,  1.03it/s]\n",
    "\n",
    "# í‰ê°€\n",
    "metrics = trainer.evaluate(test_dataset)\n",
    "print(metrics)\n",
    "# => {'accuracy': 0.8632619439868204}\n",
    "\n",
    "# ì¶”ë¡  ìˆ˜í–‰\n",
    "preds = model.predict([\n",
    "    \"ë§¤ë ¥ì ì´ê³  ì¢…ì¢… ê°ë™ì ì¸ ì—¬ì •ì…ë‹ˆë‹¤.\",\n",
    "    \"ë§¤ìš°, ë§¤ìš° ëŠë¦½ë‹ˆë‹¤.\",\n",
    "    \"ë•Œë¡œëŠ” ì§€ë£¨í•œ ì˜í™”ì…ë‹ˆë‹¤.\",\n",
    "])\n",
    "print(preds)\n",
    "# => tensor([1, 0, 0], device='cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì‚¬ìš©ì ì§€ì • ë¶„ë¥˜ í—¤ë“œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë‘ ê°€ì§€ ë‚´ì¥ ì˜µì…˜ ì™¸ì—ë„ SetFitì„ ì‚¬ìš©í•˜ë©´ ì‚¬ìš©ì ì§€ì • ë¶„ë¥˜ í—¤ë“œë¥¼ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì§€ì›ë˜ëŠ” í—¤ë“œì—ëŠ” ì‚¬ìš©ì ì§€ì • **ë¯¸ë¶„ ê°€ëŠ¥** í—¤ë“œ ë˜ëŠ” ì‚¬ìš©ì ì§€ì • **ë¯¸ë¶„ ë¶ˆê°€ëŠ¥** í—¤ë“œì˜ ë‘ ê°€ì§€ í˜•íƒœê°€ ìˆìŠµë‹ˆë‹¤. ë‘ í—¤ë“œ ëª¨ë‘ ë‹¤ìŒ ë‘ ê°€ì§€ ë©”ì„œë“œë¥¼ êµ¬í˜„í•´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì‚¬ìš©ì ì§€ì • ë¯¸ë¶„ ê°€ëŠ¥ í—¤ë“œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì‚¬ìš©ì ì§€ì • ë¯¸ë¶„ ê°€ëŠ¥ í—¤ë“œëŠ” ë‹¤ìŒ ìš”êµ¬ ì‚¬í•­ì„ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "* `nn.Module`ì„ ì„œë¸Œí´ë˜ì‹±í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "* `predict` ë©”ì„œë“œ: `(self, torch.Tensor with shape [num_inputs, embedding_size]) -> torch.Tensor with shape [num_inputs]` - ì´ ë©”ì„œë“œëŠ” ì„ë² ë”©ì„ ë¶„ë¥˜í•©ë‹ˆë‹¤. ì¶œë ¥ì€ `[0, num_classes)` ë²”ìœ„ì˜ ì •ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤.\n",
    "* `predict_proba` ë©”ì„œë“œ: `(self, torch.Tensor with shape [num_inputs, embedding_size]) -> torch.Tensor with shape [num_inputs, num_classes]` - ì´ ë©”ì„œë“œëŠ” ì„ë² ë”©ì„ ê° í´ë˜ìŠ¤ì— ëŒ€í•œ í™•ë¥ ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤. ê° ì…ë ¥ì— ëŒ€í•´ í¬ê¸°ê°€ `num_classes`ì¸ í…ì„œëŠ” í•©ê³„ê°€ 1ì´ì–´ì•¼ í•©ë‹ˆë‹¤. `torch.argmax(output, dim=-1)`ì„ ì ìš©í•˜ë©´ `predict`ì— ëŒ€í•œ ì¶œë ¥ì´ ìƒì„±ë©ë‹ˆë‹¤.\n",
    "* `get_loss_fn` ë©”ì„œë“œ: `(self) -> nn.Module` - ì´ˆê¸°í™”ëœ ì†ì‹¤ í•¨ìˆ˜(ì˜ˆ: `torch.nn.CrossEntropyLoss()`)ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "* `forward` ë©”ì„œë“œ: `(self, Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]` - Sentence Transformer ë³¸ë¬¸ì˜ ì¶œë ¥, ì¦‰ `'input_ids'`, `'token_type_ids'`, `'attention_mask'`, `'token_embeddings'` ë° `'sentence_embedding'` í‚¤ì˜ ì‚¬ì „ì„ ì§€ì •í•˜ë©´ `'logits'` í‚¤ì™€ ëª¨ì–‘ì´ `[batch_size, num_classes]`ì¸ `torch.Tensor` ê°’ì„ ê°€ì§„ ì‚¬ì „ì„ ë°˜í™˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì‚¬ìš©ì ì§€ì • ë¯¸ë¶„ ë¶ˆê°€ëŠ¥ í—¤ë“œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì‚¬ìš©ì ì§€ì • ë¯¸ë¶„ ë¶ˆê°€ëŠ¥ í—¤ë“œëŠ” ë‹¤ìŒ ìš”êµ¬ ì‚¬í•­ì„ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "* `predict` ë©”ì„œë“œ: `(self, np.array with shape [num_inputs, embedding_size]) -> np.array with shape [num_inputs]` - ì´ ë©”ì„œë“œëŠ” ì„ë² ë”©ì„ ë¶„ë¥˜í•©ë‹ˆë‹¤. ì¶œë ¥ì€ `[0, num_classes)` ë²”ìœ„ì˜ ì •ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤.\n",
    "* `predict_proba` ë©”ì„œë“œ: `(self, np.array with shape [num_inputs, embedding_size]) -> np.array with shape [num_inputs, num_classes]` - ì´ ë©”ì„œë“œëŠ” ì„ë² ë”©ì„ ê° í´ë˜ìŠ¤ì— ëŒ€í•œ í™•ë¥ ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤. ê° ì…ë ¥ì— ëŒ€í•´ í¬ê¸°ê°€ `num_classes`ì¸ ë°°ì—´ì€ í•©ê³„ê°€ 1ì´ì–´ì•¼ í•©ë‹ˆë‹¤. `np.argmax(output, dim=-1)`ì„ ì ìš©í•˜ë©´ `predict`ì— ëŒ€í•œ ì¶œë ¥ì´ ìƒì„±ë©ë‹ˆë‹¤.\n",
    "* `fit` ë©”ì„œë“œ: `(self, np.array with shape [num_inputs, embedding_size], List[Any]) -> None` - ì´ ë©”ì„œë“œëŠ” ì„ë² ë”©ì˜ `numpy` ë°°ì—´ê³¼ í•´ë‹¹ ë ˆì´ë¸” ëª©ë¡ì„ ê°€ì ¸ì™€ì•¼ í•©ë‹ˆë‹¤. ë ˆì´ë¸”ì€ ë°˜ë“œì‹œ ì •ìˆ˜ì¼ í•„ìš”ëŠ” ì—†ìŠµë‹ˆë‹¤. \n",
    "\n",
    "sklearnì˜ ë§ì€ ë¶„ë¥˜ê¸°(ì˜ˆ: [`RandomForestClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier), [`MLPClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier), [`KNeighborsClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier) ë“±)ëŠ” ì´ë¯¸ ì´ëŸ¬í•œ ìš”êµ¬ ì‚¬í•­ì„ ì¶©ì¡±í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì‚¬ìš©ì ì§€ì • (ë¯¸ë¶„ ë¶ˆê°€ëŠ¥) ë¶„ë¥˜ í—¤ë“œë¥¼ ì‚¬ìš©í•˜ì—¬ SetFit ëª¨ë¸ì„ ì´ˆê¸°í™”í•  ë•ŒëŠ” ì¼ë°˜ `__init__` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setfit import SetFitModel\n",
    "from sklearn.svm import LinearSVC\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# ìƒˆë¡œìš´ SetFit ëª¨ë¸ ì´ˆê¸°í™”\n",
    "model_body = SentenceTransformer(\"BAAI/bge-small-en-v1.5\")\n",
    "model_head = LinearSVC()\n",
    "model = SetFitModel(model_body, model_head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê·¸ëŸ° ë‹¤ìŒ ì¼ë°˜ì ì¸ ë°©ì‹ìœ¼ë¡œ í›ˆë ¨ê³¼ ì¶”ë¡ ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setfit import Trainer, TrainingArguments, sample_dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "# ë°ì´í„°ì…‹ ì¤€ë¹„\n",
    "dataset = load_dataset(\"SetFit/sst2\")\n",
    "train_dataset = sample_dataset(dataset[\"train\"], label_column=\"label\", num_samples=32)\n",
    "test_dataset = dataset[\"test\"]\n",
    "\n",
    "# í›ˆë ¨ ì¸ìˆ˜ ì¤€ë¹„\n",
    "args = TrainingArguments(\n",
    "    batch_size=32,\n",
    "    num_epochs=3,\n",
    ")\n",
    "\n",
    "# íŠ¸ë ˆì´ë„ˆ ì¤€ë¹„\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    ")\n",
    "trainer.train()\n",
    "\n",
    "# í‰ê°€\n",
    "metrics = trainer.evaluate(test_dataset)\n",
    "print(metrics)\n",
    "# => {'accuracy': 0.8638110928061504}\n",
    "\n",
    "# ì¶”ë¡  ìˆ˜í–‰\n",
    "preds = model.predict([\n",
    "    \"ë§¤ë ¥ì ì´ê³  ì¢…ì¢… ê°ë™ì ì¸ ì—¬ì •ì…ë‹ˆë‹¤.\",\n",
    "    \"ë§¤ìš°, ë§¤ìš° ëŠë¦½ë‹ˆë‹¤.\",\n",
    "    \"ë•Œë¡œëŠ” ì§€ë£¨í•œ ì˜í™”ì…ë‹ˆë‹¤.\",\n",
    "])\n",
    "print(preds)\n",
    "# => tensor([1, 0, 0], dtype=torch.int32)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
